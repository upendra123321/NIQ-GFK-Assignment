%md
## Load movies data

from pyspark.sql.types import StructType, StructField, StringType, IntegerType
schema = StructType([
    StructField("MovieID", IntegerType(), True),
    StructField("Title", StringType(), True),
    StructField("Genres", StringType(), True)
])

movies_raw_df = spark.read.csv("/FileStore/tables/movies.dat", header=True, schema=schema, sep="::")

%md
######1.1 Clean out Movies df

from pyspark.sql import regexp_extract, explode, split, col
# Extract year from the title and explode the genres
movies_df = (movies_raw_df
             .withColumn("Year", regexp_extract(col("Title"), r'\((\d{4})\)', 1).cast(IntegerType()))
             .withColumn("Genre", explode(F.split(col("Genres"), r'\|'))))

movies_raw_df.unpersist()             



%md
####2. Users

from pyspark.sql.types import StructType, StructField, StringType, IntegerType
#Load Users data
schema = StructType([
    StructField("UserID", IntegerType(), True),
    StructField("Gender", StringType(), True),
    StructField("Age", IntegerType(), True),
    StructField("Occupation", IntegerType(), True),
    StructField("Zip-Code", IntegerType(), True),
])

users_raw_df = spark.read.csv("/FileStore/tables/users.dat", header=True, schema=schema, sep="::")

%md
###### 2.1 Clean Users DF

from pyspark.sql import col
# Filter users by non-null zip code and age range 18-59
users_df = (users_raw_df
            .filter(col("Zip-Code").isNotNull())
            .filter(col("Age").between(18, 59))
            .select("UserID", "Age"))


users_raw_df.unpersist()



%md
####3. Ratings
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField("UserID", IntegerType(), True),
    StructField("MovieID", IntegerType(), True),
    StructField("Rating", IntegerType(), True),
    StructField("Timestamp", IntegerType(), True)
])

ratings_df = spark.read.csv("/FileStore/tables/ratings.dat", header=True, schema=schema, sep="::")



%md
## Aggregate all 3 DFs

from pyspark.sql import col, avg, 
# Join ratings with movies, filter movies released after 1989, group by genre and year, and calculate average rating
average_ratings_df = (ratings_df
                      .join(movies_df, on="MovieID")
                      .filter(col("Year") > 1989)
                      .groupBy("Genre", "Year")
                      .agg(avg("Rating").alias("avg_rating"))
                      .orderBy("Year"))

ratings_df.unpersist()
users_df.unpersist()
movies_df.unpersist()                      

average_ratings_df.show()   



%md
##4. Write data into table 
delta_table_path = "/FileStore/tables/average_ratings"

# Write the DataFrame as a Delta table with partitioning by 'Genre'
average_ratings_df.write \
    .format("delta") \
    .mode("overwrite") \
    .partitionBy("Genre") \
    .save(delta_table_path)

spark.sql(f"""
    CREATE TABLE IF NOT EXISTS average_ratings
    USING DELTA
    LOCATION '/FileStore/tables/average_ratings'
""")

#query data from table
result_df = spark.sql("""
    SELECT * FROM average_ratings WHERE Genre = 'Action'
""")
result_df.show()

# Drop the result_df DataFrame and table to free up memory
spark.sql("DROP TABLE IF EXISTS average_ratings")
result_df.unpersist()
